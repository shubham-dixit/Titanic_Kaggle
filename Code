# Project By
# Shubham Dixit
#Importing the libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import sys
import re as re
#Importing the dataset
sys.path.append("/home/shubhamdixit/Desktop/Titanic_project/")
train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')
dataset = [train,test]

print(train[['Pclass','Survived']].groupby(['Pclass'], as_index= False).mean().sort_values(by = 'Survived', ascending = False))
train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)
train[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)
train[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)

# SibSp and Parch

for data in dataset:
    data['Family'] = data['Parch']+data['SibSp']+1
train[['Family','Survived']].groupby(['Family'], as_index= False).mean().sort_values(by = 'Survived', ascending = False)

# Filling NaN values in Embarked
for data in dataset:
    freq_port = train.Embarked.dropna().mode()[0]
    data['Embarked']= data['Embarked'].fillna(freq_port)
train[['Embarked','Survived']].groupby(['Embarked'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)
for data in dataset:
    data['Embarked']= data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)

#Filling Nan values in Fare
for data in dataset:
    data['Fare'] = data['Fare'].fillna(train['Fare'].median())
# As there are lot of discrete values of fare, so dividing it into intervals
train['Fareband'] = pd.qcut(train['Fare'] , 4)
train[['Fareband','Survived']].groupby(['Fareband'],as_index=False).mean().sort_values(by = 'Survived', ascending = False)
for data in dataset:
    data.loc[ data['Fare'] <= 7.91, 'Fare'] = 0
    data.loc[(data['Fare'] > 7.91) & (data['Fare'] <= 14.454), 'Fare'] = 1
    data.loc[(data['Fare'] > 14.454) & (data['Fare'] <= 31), 'Fare'] = 2
    data.loc[ data['Fare'] > 31, 'Fare'] = 3
    data['Fare'] = data['Fare'].astype(int)
    
# Lets work on Age now
## As there are some Null values in Age, lets fill it by random numbres between avg-std to avg+std
for data in dataset:
	age_avg=data['Age'].mean()
	age_std=data['Age'].std()
	null_cnt=data['Age'].isnull().sum()
	rand_list=np.random.randint(age_avg-age_std,age_avg+age_std,size=null_cnt)
	data['Age'][np.isnan(data['Age'])]=rand_list
	data['Age']=data['Age'].astype(int)
    
train['Ageband'] = pd.qcut(train['Age'], 5)
train[['Ageband', 'Survived']].groupby(['Ageband'], as_index=False).mean().sort_values(by='Ageband', ascending=True)
for data in dataset:
    data.loc[ data['Age'] <= 19, 'Age'] = 0
    data.loc[(data['Age'] > 19) & (data['Age'] <= 25), 'Age'] = 1
    data.loc[(data['Age'] > 25) & (data['Age'] <= 32), 'Age'] = 2
    data.loc[(data['Age'] > 32) & (data['Age'] <= 40), 'Age'] = 3
    data.loc[ data['Age'] > 40, 'Age'] = 4
    data['Age'] = data['Age'].astype(int)

# Lets work on the (Name)
def get_title(name):
	title_search = re.search(' ([A-Za-z]+)\.', name)
	# If the title exists, extract and return it.
	if title_search:
		return title_search.group(1)
	return ""
for data in dataset:
	data['Title']=data['Name'].apply(get_title)
print(pd.crosstab(train['Title'], train['Sex']))
## Replacing all the small titles into one heading Other
for data in dataset:
    data['Title'] = data['Title'].replace(['Lady', 'Countess','Capt', 'Col',\
 	'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Other')
    data['Title']=data['Title'].replace('Mlle', 'Miss')
    data['Title']=data['Title'].replace('Ms', 'Miss')
    data['Title']=data['Title'].replace('Mme', 'Mrs')
train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean().sort_values(by = 'Survived' , ascending = False)
title_mapping = {"Mr": 1, "Miss": 2, "Mrs": 3, "Master": 4, "Rare": 5}
for data in dataset:
    data['Title'] = data['Title'].map(title_mapping)
    data['Title'] = data['Title'].fillna(0)
    data['Sex'] = data['Sex'].map( {'female': 1, 'male': 0} ).astype(int)

# Feature Extraction
drop = ['PassengerId','Parch','Name','SibSp','Family','Ticket','Cabin']
train = train.drop(drop_elements, axis = 1)
train = train.drop(['CatFare','CatAge'], axis = 1)
test  = test.drop(drop_elements, axis = 1)
train = train.values
test  = test.values

# Using SVM classification
from sklearn.svm import SVC
clas = SVC(c=5.0, gamma='auto')
clas.fit(train[:,1:], train[:,0])
pred = clas.predict(test)
print(pred)
